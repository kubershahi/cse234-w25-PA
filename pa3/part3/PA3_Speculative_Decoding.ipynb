{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "28d6b7ae9e78499a858e32c13485f552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15b7d60c434544beaa25d15d87afc1cf",
              "IPY_MODEL_55ec865cf4d64aa4a7e1152e42b16d42",
              "IPY_MODEL_3fc1af44941f4bfc996db7c6d56bd84a"
            ],
            "layout": "IPY_MODEL_52f6649f2b6a4fb0ac53ce95b92e79a4"
          }
        },
        "15b7d60c434544beaa25d15d87afc1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcb88c291fe14d148317874a7c93eee5",
            "placeholder": "​",
            "style": "IPY_MODEL_5f114d22d9224b15a3aa234b8b660491",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "55ec865cf4d64aa4a7e1152e42b16d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3327c96d801d4d9daa2588e6c417a882",
            "max": 2930076797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c65c70ee2564fd99e75724d1c453002",
            "value": 2930076797
          }
        },
        "3fc1af44941f4bfc996db7c6d56bd84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2382a424d1174b85b99c0bb928ba6da8",
            "placeholder": "​",
            "style": "IPY_MODEL_a22e7ebdc2474eb39ac4e14d434f4786",
            "value": " 2.93G/2.93G [00:01&lt;00:00, 226MB/s]"
          }
        },
        "52f6649f2b6a4fb0ac53ce95b92e79a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb88c291fe14d148317874a7c93eee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f114d22d9224b15a3aa234b8b660491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3327c96d801d4d9daa2588e6c417a882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c65c70ee2564fd99e75724d1c453002": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2382a424d1174b85b99c0bb928ba6da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a22e7ebdc2474eb39ac4e14d434f4786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "874e9413953146abbbd90f9f639f2010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdd579682eea41a186f082a187241e13",
              "IPY_MODEL_28db5938ff024a1f9a9795b715a73e38",
              "IPY_MODEL_d8c77a51faf94c499a3df3ca174115b8"
            ],
            "layout": "IPY_MODEL_b29e757abced4e41912fdffb79fc9474"
          }
        },
        "cdd579682eea41a186f082a187241e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_030945facf114bec9fd93271c9102092",
            "placeholder": "​",
            "style": "IPY_MODEL_36c8ca78e637467c8e62b5e1b5f39f85",
            "value": "model.safetensors: 100%"
          }
        },
        "28db5938ff024a1f9a9795b715a73e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a75fcd5ba77425a8a466c85029aea16",
            "max": 2930002184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd3463b94f624c909b2ab69ba53c65a1",
            "value": 2930002184
          }
        },
        "d8c77a51faf94c499a3df3ca174115b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d971f666dd846a887013ed5f3912fd4",
            "placeholder": "​",
            "style": "IPY_MODEL_f95d1abd5c50404f8cbef3e3f6aee5e2",
            "value": " 2.93G/2.93G [00:28&lt;00:00, 147MB/s]"
          }
        },
        "b29e757abced4e41912fdffb79fc9474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "030945facf114bec9fd93271c9102092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36c8ca78e637467c8e62b5e1b5f39f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a75fcd5ba77425a8a466c85029aea16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3463b94f624c909b2ab69ba53c65a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d971f666dd846a887013ed5f3912fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f95d1abd5c50404f8cbef3e3f6aee5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06643424f0134e8fb1722f21a3ae9f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e74039e6e20244889d08ecf657dd06fc",
              "IPY_MODEL_00ae8b331dde4d84995c38d76140b2d3",
              "IPY_MODEL_bc8d50645d644db2b03975637e06f076"
            ],
            "layout": "IPY_MODEL_4c69fe4c300a4736b10cbdd5fca3d95a"
          }
        },
        "e74039e6e20244889d08ecf657dd06fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09b03eda5a36438e95394931df720922",
            "placeholder": "​",
            "style": "IPY_MODEL_b384701e6ed8487696912f268fe6c1be",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "00ae8b331dde4d84995c38d76140b2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24a233ca58147348009055776c50077",
            "max": 396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b72752b64b1d4d87952e587e9192008b",
            "value": 396
          }
        },
        "bc8d50645d644db2b03975637e06f076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3a10d3c83147a3bec1b015c1f97d53",
            "placeholder": "​",
            "style": "IPY_MODEL_c3b60a265dc64754b5265ccfc324a0d3",
            "value": " 396/396 [00:00&lt;00:00, 41.7kB/s]"
          }
        },
        "4c69fe4c300a4736b10cbdd5fca3d95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b03eda5a36438e95394931df720922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b384701e6ed8487696912f268fe6c1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a24a233ca58147348009055776c50077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b72752b64b1d4d87952e587e9192008b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f3a10d3c83147a3bec1b015c1f97d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b60a265dc64754b5265ccfc324a0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6389b8503a41443793f5dbc31356c671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6e03e3720464dbda72049b5d3785b9a",
              "IPY_MODEL_29031a87713a4172a3b99908c94e9297",
              "IPY_MODEL_f78b4bdc7ad548e2a336496b5c6b8510"
            ],
            "layout": "IPY_MODEL_1cc9044169764d208ef465c39a536954"
          }
        },
        "a6e03e3720464dbda72049b5d3785b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c79340061b21458aa3a467a47b2785ec",
            "placeholder": "​",
            "style": "IPY_MODEL_e8c85b241c914ecf8deaaff0a80a74c0",
            "value": "tokenizer.json: 100%"
          }
        },
        "29031a87713a4172a3b99908c94e9297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4341495d36b940b1a8929f97d00e76bd",
            "max": 2113710,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebd774d216a54fa696ecd08becf4d13e",
            "value": 2113710
          }
        },
        "f78b4bdc7ad548e2a336496b5c6b8510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08542954295046c8b12e2bb3cd234645",
            "placeholder": "​",
            "style": "IPY_MODEL_0125ba0a80784f8b89d717b29fe871a0",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 4.70MB/s]"
          }
        },
        "1cc9044169764d208ef465c39a536954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79340061b21458aa3a467a47b2785ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c85b241c914ecf8deaaff0a80a74c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4341495d36b940b1a8929f97d00e76bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd774d216a54fa696ecd08becf4d13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08542954295046c8b12e2bb3cd234645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0125ba0a80784f8b89d717b29fe871a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7540f2ff3a14dbabd73a6d5284fb369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54b0efc9087242bea54b29a03c5479d8",
              "IPY_MODEL_cbc350b7d98d4ed9a713c3c8930ad20c",
              "IPY_MODEL_60991d1eeb334d8380d32859c296dad0"
            ],
            "layout": "IPY_MODEL_3c71ab5a3e0f4b5bb14d4acd0d9ea7e1"
          }
        },
        "54b0efc9087242bea54b29a03c5479d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_813602e2d1544ee19ec8b536ea335872",
            "placeholder": "​",
            "style": "IPY_MODEL_a0cb5e51845d4ae7b7c0ae1573acede4",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "cbc350b7d98d4ed9a713c3c8930ad20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497e4f25396e44dcb72161e8b293dc48",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eafb87d8c1fe45a7b39b5ba051b1527b",
            "value": 99
          }
        },
        "60991d1eeb334d8380d32859c296dad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f81442ca1eb5402d839f3491a347d37f",
            "placeholder": "​",
            "style": "IPY_MODEL_c304eea4cd764862aff86e8b384047af",
            "value": " 99.0/99.0 [00:00&lt;00:00, 2.51kB/s]"
          }
        },
        "3c71ab5a3e0f4b5bb14d4acd0d9ea7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813602e2d1544ee19ec8b536ea335872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0cb5e51845d4ae7b7c0ae1573acede4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "497e4f25396e44dcb72161e8b293dc48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eafb87d8c1fe45a7b39b5ba051b1527b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f81442ca1eb5402d839f3491a347d37f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c304eea4cd764862aff86e8b384047af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf7d51c39bfc42ba842922d3da82df94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_467c15c089fe4ad2894c43ce5381882f",
              "IPY_MODEL_80f45bbdc82f45d8a0b2bdba56f445b1",
              "IPY_MODEL_3d61ddfade8b473aaaab9b07d9f8b9a2"
            ],
            "layout": "IPY_MODEL_789a787599064943a54a9b9ed5d35191"
          }
        },
        "467c15c089fe4ad2894c43ce5381882f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d8ef93f85ba4d2691286f2ce0c79bfe",
            "placeholder": "​",
            "style": "IPY_MODEL_e097fdb7431446b496aebb450c8ba9c8",
            "value": "config.json: 100%"
          }
        },
        "80f45bbdc82f45d8a0b2bdba56f445b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b2c3c3f68b54aea8e279510969bd98a",
            "max": 569,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4d0bc1fa31340378aa2cf0599fea3a3",
            "value": 569
          }
        },
        "3d61ddfade8b473aaaab9b07d9f8b9a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36ffefd795a44fe1990bc9a62c00670a",
            "placeholder": "​",
            "style": "IPY_MODEL_e099d0cb11264b6a99061c30e319d9d2",
            "value": " 569/569 [00:00&lt;00:00, 48.9kB/s]"
          }
        },
        "789a787599064943a54a9b9ed5d35191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8ef93f85ba4d2691286f2ce0c79bfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e097fdb7431446b496aebb450c8ba9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b2c3c3f68b54aea8e279510969bd98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4d0bc1fa31340378aa2cf0599fea3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36ffefd795a44fe1990bc9a62c00670a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e099d0cb11264b6a99061c30e319d9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ec3b1311d6b4af593eef26edef6ea9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4b150e1d6fd472fb4c2d2af61f26198",
              "IPY_MODEL_31416306a98e481fa8c069833c933e5c",
              "IPY_MODEL_7cabfab5066a488094c136a6f6657a81"
            ],
            "layout": "IPY_MODEL_ca69f254886846368b096767a8b6e9d3"
          }
        },
        "e4b150e1d6fd472fb4c2d2af61f26198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac1d77c7a594d95915fbdcb80ae7984",
            "placeholder": "​",
            "style": "IPY_MODEL_260e13c8285f45f5a40040bb9ccf609c",
            "value": "model.safetensors: 100%"
          }
        },
        "31416306a98e481fa8c069833c933e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bbf33c70cec40fe80b9613bf6a7300c",
            "max": 374998696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af2ce568a1c74314ba49ab2f19311b52",
            "value": 374998696
          }
        },
        "7cabfab5066a488094c136a6f6657a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a629cc776674c999b8a4264262c0ea5",
            "placeholder": "​",
            "style": "IPY_MODEL_c28138150762426cba3fda178354b6a6",
            "value": " 375M/375M [00:04&lt;00:00, 61.1MB/s]"
          }
        },
        "ca69f254886846368b096767a8b6e9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac1d77c7a594d95915fbdcb80ae7984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260e13c8285f45f5a40040bb9ccf609c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bbf33c70cec40fe80b9613bf6a7300c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2ce568a1c74314ba49ab2f19311b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a629cc776674c999b8a4264262c0ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c28138150762426cba3fda178354b6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSE 234 Programming Assignment 3: Speculative Decoding"
      ],
      "metadata": {
        "id": "pmRSlH1L5r-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "zDuj8yGG6EXg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "52T8Gw-R5lup"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from typing import List, Tuple, Dict, Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speculative Decoding"
      ],
      "metadata": {
        "id": "NwyZ4tAb6Gu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeculativeDecoder:\n",
        "    def __init__(self, target_model_name: str, draft_model_name: str, device: str = \"cuda\"):\n",
        "        self.device = device\n",
        "        self.target_model, self.target_tokenizer = self.initialize_target_model(target_model_name)\n",
        "        self.draft_model, self.draft_tokenizer = self.initialize_draft_model(draft_model_name)\n",
        "        assert self.target_tokenizer.vocab == self.draft_tokenizer.vocab, \"Tokenizers must be compatible\"\n",
        "\n",
        "        # Ensure PAD token is set\n",
        "        if self.target_tokenizer.pad_token is None:\n",
        "            self.target_tokenizer.pad_token = self.target_tokenizer.eos_token\n",
        "        if self.draft_tokenizer.pad_token is None:\n",
        "            self.draft_tokenizer.pad_token = self.draft_tokenizer.eos_token\n",
        "\n",
        "    def initialize_target_model(self, model_name: str):\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name, device_map=\"cuda:0\"\n",
        "        ).eval()\n",
        "        model.config.use_cache = True\n",
        "        return model, tokenizer\n",
        "\n",
        "    def initialize_draft_model(self, model_name: str):\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name, device_map=\"cuda:0\"\n",
        "        ).eval()\n",
        "        model.config.use_cache = True\n",
        "        return model, tokenizer\n",
        "\n",
        "    def generate_draft_tokens(self, input_ids: torch.Tensor, attention_mask: torch.Tensor, num_speculative_tokens) -> torch.Tensor:\n",
        "        with torch.no_grad():\n",
        "            output = self.draft_model.generate(\n",
        "                input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_new_tokens=num_speculative_tokens,\n",
        "                pad_token_id=self.draft_tokenizer.pad_token_id,\n",
        "                do_sample=False\n",
        "                # do_sample=True,\n",
        "                # top_k=25,\n",
        "                # temperature=0.25\n",
        "            )\n",
        "        return output[:, -num_speculative_tokens:]\n",
        "\n",
        "    def verify_tokens_vectorized(self, input_ids: torch.Tensor, draft_tokens: torch.Tensor, attention_mask: torch.Tensor) -> Tuple[List[int], int]:\n",
        "        combined_ids = torch.cat([input_ids, draft_tokens], dim=1)\n",
        "        combined_mask = torch.cat([attention_mask, torch.ones_like(draft_tokens, dtype=torch.long)], dim=1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = self.target_model(input_ids=combined_ids, attention_mask=combined_mask)\n",
        "\n",
        "        # Extract logits corresponding to the draft token positions.\n",
        "        logits = outputs.logits[:, input_ids.shape[1] - 1:-1, :]\n",
        "        predicted_tokens = logits.argmax(dim=-1)\n",
        "\n",
        "        # Vectorized comparison between draft and predicted tokens.\n",
        "        correct = (draft_tokens == predicted_tokens)\n",
        "        mismatches = (~correct[0]).nonzero(as_tuple=True)[0]\n",
        "\n",
        "        if mismatches.numel() > 0:\n",
        "            first_mismatch = mismatches[0].item()\n",
        "            accepted_tokens = draft_tokens[0, :first_mismatch].tolist()\n",
        "            return accepted_tokens, first_mismatch\n",
        "        else:\n",
        "            accepted_tokens = draft_tokens[0].tolist()\n",
        "            return accepted_tokens, draft_tokens.shape[1]\n",
        "\n",
        "    def speculative_decode(self, prompt: str, max_tokens: int = 100, num_speculative_tokens: int = 15) -> str:\n",
        "        inputs = self.target_tokenizer(prompt, return_tensors=\"pt\", padding=True).to(self.device)\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "        initial_length = input_ids.shape[1]\n",
        "\n",
        "        total_draft_tokens_proposed = 0\n",
        "        total_draft_tokens_accepted = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        while (input_ids.shape[1] - initial_length) < max_tokens:\n",
        "            draft_tokens = self.generate_draft_tokens(input_ids, attention_mask, num_speculative_tokens)\n",
        "            total_draft_tokens_proposed += draft_tokens.shape[1]\n",
        "            accepted_tokens, first_rejected = self.verify_tokens_vectorized(input_ids, draft_tokens, attention_mask)\n",
        "            total_draft_tokens_accepted += len(accepted_tokens)\n",
        "\n",
        "            # Append accepted tokens\n",
        "            if accepted_tokens:\n",
        "                accepted_tensor = torch.tensor([accepted_tokens], dtype=torch.long).to(self.device)\n",
        "                input_ids = torch.cat([input_ids, accepted_tensor], dim=1)\n",
        "                attention_mask = torch.cat([attention_mask, torch.ones_like(accepted_tensor, dtype=torch.long)], dim=1)\n",
        "                # Stop if the EOS token is encountered in accepted tokens.\n",
        "                if accepted_tensor[0, -1] == self.target_tokenizer.eos_token_id:\n",
        "                    break\n",
        "\n",
        "            # If any draft token was rejected, fall back to a single token generation.\n",
        "            if first_rejected < draft_tokens.shape[1]:\n",
        "                with torch.no_grad():\n",
        "                    output = self.target_model.generate(\n",
        "                        input_ids, max_new_tokens=1,\n",
        "                        attention_mask=attention_mask,\n",
        "                        pad_token_id=self.target_tokenizer.pad_token_id,\n",
        "                        do_sample=False\n",
        "                        # do_sample=True,\n",
        "                        # top_k=25,\n",
        "                        # temperature=0.25\n",
        "                    )\n",
        "                input_ids = torch.cat([input_ids, output[:, -1:]], dim=1)\n",
        "                attention_mask = torch.cat([attention_mask, torch.ones((1, 1), dtype=torch.long).to(self.device)], dim=1)\n",
        "                # Stop if the EOS token is encountered in the fallback token.\n",
        "                if output[0, -1] == self.target_tokenizer.eos_token_id:\n",
        "                    break\n",
        "\n",
        "        elapsed_time = time.time() - start_time\n",
        "        generated_tokens = input_ids.shape[1] - initial_length\n",
        "        acceptance_rate = total_draft_tokens_accepted / total_draft_tokens_proposed if total_draft_tokens_proposed > 0 else 0\n",
        "\n",
        "        print(f\"Generated {generated_tokens} tokens in {elapsed_time:.2f} seconds\")\n",
        "        print(f\"Tokens per second: {generated_tokens / elapsed_time:.2f}\")\n",
        "        print(f\"Draft token acceptance rate: {acceptance_rate:.2%}\")\n",
        "\n",
        "        return self.target_tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    def benchmark(self, prompt: str, max_tokens: int = 100,\n",
        "                  num_runs: int = 3, compare_baseline: bool = True) -> Dict:\n",
        "        \"\"\"\n",
        "        Benchmark the speculative decoder against baseline decoding.\n",
        "\n",
        "        Args:\n",
        "            prompt: Input text.\n",
        "            max_tokens: Maximum number of tokens to generate.\n",
        "            num_runs: Number of benchmark runs.\n",
        "            compare_baseline: Whether to compare with baseline (non-speculative) decoding.\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with benchmark results.\n",
        "        \"\"\"\n",
        "        results = {\n",
        "            \"speculative\": {\"times\": [], \"tokens_per_second\": []},\n",
        "            \"baseline\": {\"times\": [], \"tokens_per_second\": []} if compare_baseline else None\n",
        "        }\n",
        "\n",
        "        # Benchmark speculative decoding.\n",
        "        for _ in range(num_runs):\n",
        "            start_time = time.time()\n",
        "            output = self.speculative_decode(prompt, max_tokens=max_tokens)\n",
        "            elapsed = time.time() - start_time\n",
        "            prompt_len = len(self.target_tokenizer(prompt)[\"input_ids\"])\n",
        "            output_tokens = len(self.target_tokenizer.encode(output)) - prompt_len\n",
        "            tps = output_tokens / elapsed\n",
        "            results[\"speculative\"][\"times\"].append(elapsed)\n",
        "            results[\"speculative\"][\"tokens_per_second\"].append(tps)\n",
        "\n",
        "        # Benchmark baseline decoding.\n",
        "        if compare_baseline:\n",
        "            for _ in range(num_runs):\n",
        "                inputs = self.target_tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
        "                input_ids = inputs[\"input_ids\"].to(self.device)\n",
        "                attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
        "                start_time = time.time()\n",
        "                with torch.no_grad():\n",
        "                    output_ids = self.target_model.generate(\n",
        "                        input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        max_length=input_ids.shape[1] + max_tokens,\n",
        "                        do_sample=False,\n",
        "                        pad_token_id=self.target_tokenizer.pad_token_id\n",
        "                    )\n",
        "                elapsed = time.time() - start_time\n",
        "                output_tokens = output_ids.shape[1] - input_ids.shape[1]\n",
        "                tps = output_tokens / elapsed\n",
        "                results[\"baseline\"][\"times\"].append(elapsed)\n",
        "                results[\"baseline\"][\"tokens_per_second\"].append(tps)\n",
        "\n",
        "        for method in results.keys():\n",
        "            if results[method] is not None:\n",
        "                avg_time = sum(results[method][\"times\"]) / num_runs\n",
        "                avg_tps = sum(results[method][\"tokens_per_second\"]) / num_runs\n",
        "                results[method][\"avg_time\"] = avg_time\n",
        "                results[method][\"avg_tokens_per_second\"] = avg_tps\n",
        "\n",
        "        if compare_baseline:\n",
        "            speedup = results[\"baseline\"][\"avg_time\"] / results[\"speculative\"][\"avg_time\"]\n",
        "            results[\"speedup\"] = speedup\n",
        "            results[\"latency_reduction\"] = (1 - results[\"speculative\"][\"avg_time\"] / results[\"baseline\"][\"avg_time\"]) * 100\n",
        "            # print(f\"Speculative decoding speedup: {speedup:.2f}x\")\n",
        "            # print(f\"Latency reduction: {results['latency_reduction']:.2f}%\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "        return results\n",
        "\n",
        "    def bonus_benchmark(self, prompt: str, max_tokens: int = 100,\n",
        "                        num_runs: int = 3, num_speculative_tokens: int = 15, compare_baseline: bool = True) -> Dict:\n",
        "      \"\"\"\n",
        "      Benchmark the speculative decoder against baseline decoding.\n",
        "\n",
        "      Args:\n",
        "          prompt: Input text.\n",
        "          max_tokens: Maximum number of tokens to generate.\n",
        "          num_runs: Number of benchmark runs.\n",
        "          compare_baseline: Whether to compare with baseline (non-speculative) decoding.\n",
        "\n",
        "      Returns:\n",
        "          Dictionary with benchmark results.\n",
        "      \"\"\"\n",
        "      results = {\n",
        "          \"speculative\": {\"times\": [], \"tokens_per_second\": []},\n",
        "          \"baseline\": {\"times\": [], \"tokens_per_second\": []} if compare_baseline else None\n",
        "      }\n",
        "\n",
        "      # Benchmark speculative decoding.\n",
        "      for _ in range(num_runs):\n",
        "          start_time = time.time()\n",
        "          output = self.speculative_decode(prompt, max_tokens=max_tokens, num_speculative_tokens=num_speculative_tokens)\n",
        "          elapsed = time.time() - start_time\n",
        "          prompt_len = len(self.target_tokenizer(prompt)[\"input_ids\"])\n",
        "          output_tokens = len(self.target_tokenizer.encode(output)) - prompt_len\n",
        "          tps = output_tokens / elapsed\n",
        "          results[\"speculative\"][\"times\"].append(elapsed)\n",
        "          results[\"speculative\"][\"tokens_per_second\"].append(tps)\n",
        "\n",
        "      # Benchmark baseline decoding.\n",
        "      if compare_baseline:\n",
        "          for _ in range(num_runs):\n",
        "              inputs = self.target_tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
        "              input_ids = inputs[\"input_ids\"].to(self.device)\n",
        "              attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
        "              start_time = time.time()\n",
        "              with torch.no_grad():\n",
        "                  output_ids = self.target_model.generate(\n",
        "                      input_ids,\n",
        "                      attention_mask=attention_mask,\n",
        "                      max_length=input_ids.shape[1] + max_tokens,\n",
        "                      do_sample=False,\n",
        "                      pad_token_id=self.target_tokenizer.pad_token_id\n",
        "                  )\n",
        "              elapsed = time.time() - start_time\n",
        "              output_tokens = output_ids.shape[1] - input_ids.shape[1]\n",
        "              tps = output_tokens / elapsed\n",
        "              results[\"baseline\"][\"times\"].append(elapsed)\n",
        "              results[\"baseline\"][\"tokens_per_second\"].append(tps)\n",
        "\n",
        "      for method in results.keys():\n",
        "          if results[method] is not None:\n",
        "              avg_time = sum(results[method][\"times\"]) / num_runs\n",
        "              avg_tps = sum(results[method][\"tokens_per_second\"]) / num_runs\n",
        "              results[method][\"avg_time\"] = avg_time\n",
        "              results[method][\"avg_tokens_per_second\"] = avg_tps\n",
        "\n",
        "      if compare_baseline:\n",
        "          speedup = results[\"baseline\"][\"avg_time\"] / results[\"speculative\"][\"avg_time\"]\n",
        "          results[\"speedup\"] = speedup\n",
        "          results[\"latency_reduction\"] = (1 - results[\"speculative\"][\"avg_time\"] / results[\"baseline\"][\"avg_time\"]) * 100\n",
        "          # print(f\"Speculative decoding speedup: {speedup:.2f}x\")\n",
        "          # print(f\"Latency reduction: {results['latency_reduction']:.2f}%\")\n",
        "\n",
        "      return results"
      ],
      "metadata": {
        "id": "VIvmDG725x8H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 - Test"
      ],
      "metadata": {
        "id": "XNzh3cG-6KM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_model_name = \"EleutherAI/pythia-1.4b-deduped\"  # Larger target model\n",
        "draft_model_name = \"EleutherAI/pythia-160m-deduped\"   # Smaller draft model\n",
        "\n",
        "\n",
        "# Initialize speculative decoder\n",
        "decoder = SpeculativeDecoder(\n",
        "    target_model_name=target_model_name,\n",
        "    draft_model_name=draft_model_name,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Test prompts\n",
        "test_prompts = [\n",
        "    \"The future of Artificial Intelligence is\",\n",
        "    \"Write a short story about a robot learning to feel emotions:\",\n",
        "    \"Write the lyrics to the song 'Happy Birthday'.\"\n",
        "]\n",
        "\n",
        "# Run benchmark on test prompts\n",
        "for i, prompt in enumerate(test_prompts):\n",
        "    print(f\"\\nBenchmarking Prompt {i+1}:\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "\n",
        "    results = decoder.benchmark(\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,\n",
        "        num_runs=3,\n",
        "        compare_baseline=True\n",
        "    )\n",
        "\n",
        "    print(f\"Average speculative decoding time: {results['speculative']['avg_time']:.2f} seconds\")\n",
        "    print(f\"Average speculative tokens per second: {results['speculative']['avg_tokens_per_second']:.2f}\")\n",
        "\n",
        "    if results[\"baseline\"] is not None:\n",
        "        print(f\"Average baseline decoding time: {results['baseline']['avg_time']:.2f} seconds\")\n",
        "        print(f\"Average baseline tokens per second: {results['baseline']['avg_tokens_per_second']:.2f}\")\n",
        "        print(f\"Speedup: {results['speedup']:.2f}x\")\n",
        "        print(f\"Latency reduction: {results['latency_reduction']:.2f}%\")"
      ],
      "metadata": {
        "id": "YyNXbA-26Cpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90621f2b-1a62-440f-85ec-1ac641494c04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Benchmarking Prompt 1:\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 106 tokens in 2.04 seconds\n",
            "Tokens per second: 52.06\n",
            "Draft token acceptance rate: 87.50%\n",
            "Generated 106 tokens in 1.92 seconds\n",
            "Tokens per second: 55.24\n",
            "Draft token acceptance rate: 87.50%\n",
            "Generated 106 tokens in 1.97 seconds\n",
            "Tokens per second: 53.74\n",
            "Draft token acceptance rate: 87.50%\n",
            "Average speculative decoding time: 1.98 seconds\n",
            "Average speculative tokens per second: 53.65\n",
            "Average baseline decoding time: 2.65 seconds\n",
            "Average baseline tokens per second: 37.86\n",
            "Speedup: 1.34x\n",
            "Latency reduction: 25.28%\n",
            "\n",
            "Benchmarking Prompt 2:\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 114 tokens in 2.07 seconds\n",
            "Tokens per second: 54.98\n",
            "Draft token acceptance rate: 94.17%\n",
            "Generated 114 tokens in 2.06 seconds\n",
            "Tokens per second: 55.41\n",
            "Draft token acceptance rate: 94.17%\n",
            "Generated 114 tokens in 2.14 seconds\n",
            "Tokens per second: 53.37\n",
            "Draft token acceptance rate: 94.17%\n",
            "Average speculative decoding time: 2.09 seconds\n",
            "Average speculative tokens per second: 54.55\n",
            "Average baseline decoding time: 2.79 seconds\n",
            "Average baseline tokens per second: 36.12\n",
            "Speedup: 1.33x\n",
            "Latency reduction: 25.01%\n",
            "\n",
            "Benchmarking Prompt 3:\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 108 tokens in 1.97 seconds\n",
            "Tokens per second: 54.83\n",
            "Draft token acceptance rate: 89.17%\n",
            "Generated 108 tokens in 2.14 seconds\n",
            "Tokens per second: 50.43\n",
            "Draft token acceptance rate: 89.17%\n",
            "Generated 108 tokens in 2.31 seconds\n",
            "Tokens per second: 46.70\n",
            "Draft token acceptance rate: 89.17%\n",
            "Average speculative decoding time: 2.14 seconds\n",
            "Average speculative tokens per second: 50.61\n",
            "Average baseline decoding time: 2.52 seconds\n",
            "Average baseline tokens per second: 39.66\n",
            "Speedup: 1.18x\n",
            "Latency reduction: 15.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Experiments"
      ],
      "metadata": {
        "id": "1O1EORd26MdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_model_name = \"EleutherAI/pythia-1.4b-deduped\"  # Larger target model\n",
        "draft_model_name = \"EleutherAI/pythia-160m-deduped\"   # Smaller draft model\n",
        "\n",
        "\n",
        "# Initialize speculative decoder\n",
        "decoder = SpeculativeDecoder(\n",
        "    target_model_name=target_model_name,\n",
        "    draft_model_name=draft_model_name,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Test prompts\n",
        "test_prompts = [\n",
        "    \"The future of Artificial Intelligence is\",\n",
        "    \"Write a short story about a robot learning to feel emotions:\",\n",
        "    \"Write the lyrics to the song 'Happy Birthday'.\"\n",
        "]\n",
        "\n",
        "\n",
        "max_tokens_list = [250, 500, 1000]\n",
        "speculative_tokens = [10, 25, 100, 250]\n",
        "# Run benchmark on test prompts\n",
        "for max_token in max_tokens_list:\n",
        "  for speculative_token in speculative_tokens:\n",
        "    print(f\"\\nBenchmarking with {max_token} max tokens and {speculative_token} speculative tokens:\")\n",
        "    for i, prompt in enumerate(test_prompts):\n",
        "      print(f\"\\nPrompt: {prompt}\")\n",
        "\n",
        "      results = decoder.bonus_benchmark(\n",
        "          prompt=prompt,\n",
        "          max_tokens=max_token,\n",
        "          num_speculative_tokens=speculative_token,\n",
        "          num_runs=3,\n",
        "          compare_baseline=True\n",
        "      )\n",
        "\n",
        "      print(f\"Average speculative decoding time: {results['speculative']['avg_time']:.2f} seconds\")\n",
        "      print(f\"Average speculative tokens per second: {results['speculative']['avg_tokens_per_second']:.2f}\")\n",
        "\n",
        "      if results[\"baseline\"] is not None:\n",
        "          print(f\"Average baseline decoding time: {results['baseline']['avg_time']:.2f} seconds\")\n",
        "          print(f\"Average baseline tokens per second: {results['baseline']['avg_tokens_per_second']:.2f}\")\n",
        "          print(f\"Speedup: {results['speedup']:.2f}x\")\n",
        "          print(f\"Latency reduction: {results['latency_reduction']:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "28d6b7ae9e78499a858e32c13485f552",
            "15b7d60c434544beaa25d15d87afc1cf",
            "55ec865cf4d64aa4a7e1152e42b16d42",
            "3fc1af44941f4bfc996db7c6d56bd84a",
            "52f6649f2b6a4fb0ac53ce95b92e79a4",
            "bcb88c291fe14d148317874a7c93eee5",
            "5f114d22d9224b15a3aa234b8b660491",
            "3327c96d801d4d9daa2588e6c417a882",
            "2c65c70ee2564fd99e75724d1c453002",
            "2382a424d1174b85b99c0bb928ba6da8",
            "a22e7ebdc2474eb39ac4e14d434f4786",
            "874e9413953146abbbd90f9f639f2010",
            "cdd579682eea41a186f082a187241e13",
            "28db5938ff024a1f9a9795b715a73e38",
            "d8c77a51faf94c499a3df3ca174115b8",
            "b29e757abced4e41912fdffb79fc9474",
            "030945facf114bec9fd93271c9102092",
            "36c8ca78e637467c8e62b5e1b5f39f85",
            "7a75fcd5ba77425a8a466c85029aea16",
            "bd3463b94f624c909b2ab69ba53c65a1",
            "0d971f666dd846a887013ed5f3912fd4",
            "f95d1abd5c50404f8cbef3e3f6aee5e2",
            "06643424f0134e8fb1722f21a3ae9f56",
            "e74039e6e20244889d08ecf657dd06fc",
            "00ae8b331dde4d84995c38d76140b2d3",
            "bc8d50645d644db2b03975637e06f076",
            "4c69fe4c300a4736b10cbdd5fca3d95a",
            "09b03eda5a36438e95394931df720922",
            "b384701e6ed8487696912f268fe6c1be",
            "a24a233ca58147348009055776c50077",
            "b72752b64b1d4d87952e587e9192008b",
            "7f3a10d3c83147a3bec1b015c1f97d53",
            "c3b60a265dc64754b5265ccfc324a0d3",
            "6389b8503a41443793f5dbc31356c671",
            "a6e03e3720464dbda72049b5d3785b9a",
            "29031a87713a4172a3b99908c94e9297",
            "f78b4bdc7ad548e2a336496b5c6b8510",
            "1cc9044169764d208ef465c39a536954",
            "c79340061b21458aa3a467a47b2785ec",
            "e8c85b241c914ecf8deaaff0a80a74c0",
            "4341495d36b940b1a8929f97d00e76bd",
            "ebd774d216a54fa696ecd08becf4d13e",
            "08542954295046c8b12e2bb3cd234645",
            "0125ba0a80784f8b89d717b29fe871a0",
            "c7540f2ff3a14dbabd73a6d5284fb369",
            "54b0efc9087242bea54b29a03c5479d8",
            "cbc350b7d98d4ed9a713c3c8930ad20c",
            "60991d1eeb334d8380d32859c296dad0",
            "3c71ab5a3e0f4b5bb14d4acd0d9ea7e1",
            "813602e2d1544ee19ec8b536ea335872",
            "a0cb5e51845d4ae7b7c0ae1573acede4",
            "497e4f25396e44dcb72161e8b293dc48",
            "eafb87d8c1fe45a7b39b5ba051b1527b",
            "f81442ca1eb5402d839f3491a347d37f",
            "c304eea4cd764862aff86e8b384047af",
            "cf7d51c39bfc42ba842922d3da82df94",
            "467c15c089fe4ad2894c43ce5381882f",
            "80f45bbdc82f45d8a0b2bdba56f445b1",
            "3d61ddfade8b473aaaab9b07d9f8b9a2",
            "789a787599064943a54a9b9ed5d35191",
            "1d8ef93f85ba4d2691286f2ce0c79bfe",
            "e097fdb7431446b496aebb450c8ba9c8",
            "0b2c3c3f68b54aea8e279510969bd98a",
            "b4d0bc1fa31340378aa2cf0599fea3a3",
            "36ffefd795a44fe1990bc9a62c00670a",
            "e099d0cb11264b6a99061c30e319d9d2",
            "4ec3b1311d6b4af593eef26edef6ea9d",
            "e4b150e1d6fd472fb4c2d2af61f26198",
            "31416306a98e481fa8c069833c933e5c",
            "7cabfab5066a488094c136a6f6657a81",
            "ca69f254886846368b096767a8b6e9d3",
            "fac1d77c7a594d95915fbdcb80ae7984",
            "260e13c8285f45f5a40040bb9ccf609c",
            "1bbf33c70cec40fe80b9613bf6a7300c",
            "af2ce568a1c74314ba49ab2f19311b52",
            "5a629cc776674c999b8a4264262c0ea5",
            "c28138150762426cba3fda178354b6a6"
          ]
        },
        "id": "1466QgCMTX1H",
        "outputId": "eefd08f1-22db-4fe4-c720-5455ae124ef8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:  88%|########8 | 2.58G/2.93G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28d6b7ae9e78499a858e32c13485f552"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.93G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "874e9413953146abbbd90f9f639f2010"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06643424f0134e8fb1722f21a3ae9f56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6389b8503a41443793f5dbc31356c671"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7540f2ff3a14dbabd73a6d5284fb369"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/569 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf7d51c39bfc42ba842922d3da82df94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/375M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ec3b1311d6b4af593eef26edef6ea9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Benchmarking with 250 max tokens and 10 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 251 tokens in 6.75 seconds\n",
            "Tokens per second: 37.17\n",
            "Draft token acceptance rate: 96.15%\n",
            "Generated 251 tokens in 5.90 seconds\n",
            "Tokens per second: 42.52\n",
            "Draft token acceptance rate: 96.15%\n",
            "Generated 251 tokens in 5.66 seconds\n",
            "Tokens per second: 44.32\n",
            "Draft token acceptance rate: 96.15%\n",
            "Average speculative decoding time: 6.11 seconds\n",
            "Average speculative tokens per second: 41.31\n",
            "Average baseline decoding time: 6.41 seconds\n",
            "Average baseline tokens per second: 39.04\n",
            "Speedup: 1.05x\n",
            "Latency reduction: 4.61%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 259 tokens in 5.98 seconds\n",
            "Tokens per second: 43.30\n",
            "Draft token acceptance rate: 99.23%\n",
            "Generated 259 tokens in 6.69 seconds\n",
            "Tokens per second: 38.70\n",
            "Draft token acceptance rate: 99.23%\n",
            "Generated 259 tokens in 6.07 seconds\n",
            "Tokens per second: 42.65\n",
            "Draft token acceptance rate: 99.23%\n",
            "Average speculative decoding time: 6.25 seconds\n",
            "Average speculative tokens per second: 41.53\n",
            "Average baseline decoding time: 6.45 seconds\n",
            "Average baseline tokens per second: 38.76\n",
            "Speedup: 1.03x\n",
            "Latency reduction: 3.12%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 253 tokens in 5.99 seconds\n",
            "Tokens per second: 42.23\n",
            "Draft token acceptance rate: 96.92%\n",
            "Generated 253 tokens in 6.35 seconds\n",
            "Tokens per second: 39.82\n",
            "Draft token acceptance rate: 96.92%\n",
            "Generated 253 tokens in 5.87 seconds\n",
            "Tokens per second: 43.13\n",
            "Draft token acceptance rate: 96.92%\n",
            "Average speculative decoding time: 6.07 seconds\n",
            "Average speculative tokens per second: 41.72\n",
            "Average baseline decoding time: 6.47 seconds\n",
            "Average baseline tokens per second: 38.62\n",
            "Speedup: 1.07x\n",
            "Latency reduction: 6.22%\n",
            "\n",
            "Benchmarking with 250 max tokens and 25 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 251 tokens in 4.30 seconds\n",
            "Tokens per second: 58.36\n",
            "Draft token acceptance rate: 90.91%\n",
            "Generated 251 tokens in 4.71 seconds\n",
            "Tokens per second: 53.27\n",
            "Draft token acceptance rate: 90.91%\n",
            "Generated 251 tokens in 4.20 seconds\n",
            "Tokens per second: 59.78\n",
            "Draft token acceptance rate: 90.91%\n",
            "Average speculative decoding time: 4.41 seconds\n",
            "Average speculative tokens per second: 57.12\n",
            "Average baseline decoding time: 6.43 seconds\n",
            "Average baseline tokens per second: 38.88\n",
            "Speedup: 1.46x\n",
            "Latency reduction: 31.51%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 259 tokens in 4.30 seconds\n",
            "Tokens per second: 60.22\n",
            "Draft token acceptance rate: 93.82%\n",
            "Generated 259 tokens in 4.37 seconds\n",
            "Tokens per second: 59.31\n",
            "Draft token acceptance rate: 93.82%\n",
            "Generated 259 tokens in 4.69 seconds\n",
            "Tokens per second: 55.20\n",
            "Draft token acceptance rate: 93.82%\n",
            "Average speculative decoding time: 4.45 seconds\n",
            "Average speculative tokens per second: 58.23\n",
            "Average baseline decoding time: 6.40 seconds\n",
            "Average baseline tokens per second: 39.06\n",
            "Speedup: 1.44x\n",
            "Latency reduction: 30.43%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 253 tokens in 4.63 seconds\n",
            "Tokens per second: 54.65\n",
            "Draft token acceptance rate: 91.64%\n",
            "Generated 253 tokens in 4.23 seconds\n",
            "Tokens per second: 59.80\n",
            "Draft token acceptance rate: 91.64%\n",
            "Generated 253 tokens in 4.56 seconds\n",
            "Tokens per second: 55.46\n",
            "Draft token acceptance rate: 91.64%\n",
            "Average speculative decoding time: 4.48 seconds\n",
            "Average speculative tokens per second: 56.62\n",
            "Average baseline decoding time: 6.39 seconds\n",
            "Average baseline tokens per second: 39.14\n",
            "Speedup: 1.43x\n",
            "Latency reduction: 29.95%\n",
            "\n",
            "Benchmarking with 250 max tokens and 100 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 301 tokens in 5.26 seconds\n",
            "Tokens per second: 57.20\n",
            "Draft token acceptance rate: 75.00%\n",
            "Generated 301 tokens in 4.71 seconds\n",
            "Tokens per second: 63.86\n",
            "Draft token acceptance rate: 75.00%\n",
            "Generated 301 tokens in 4.70 seconds\n",
            "Tokens per second: 64.00\n",
            "Draft token acceptance rate: 75.00%\n",
            "Average speculative decoding time: 4.89 seconds\n",
            "Average speculative tokens per second: 61.46\n",
            "Average baseline decoding time: 6.47 seconds\n",
            "Average baseline tokens per second: 38.66\n",
            "Speedup: 1.32x\n",
            "Latency reduction: 24.32%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 309 tokens in 4.72 seconds\n",
            "Tokens per second: 65.48\n",
            "Draft token acceptance rate: 77.00%\n",
            "Generated 309 tokens in 5.32 seconds\n",
            "Tokens per second: 58.11\n",
            "Draft token acceptance rate: 77.00%\n",
            "Generated 309 tokens in 5.47 seconds\n",
            "Tokens per second: 56.45\n",
            "Draft token acceptance rate: 77.00%\n",
            "Average speculative decoding time: 5.17 seconds\n",
            "Average speculative tokens per second: 59.99\n",
            "Average baseline decoding time: 6.52 seconds\n",
            "Average baseline tokens per second: 38.35\n",
            "Speedup: 1.26x\n",
            "Latency reduction: 20.70%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 303 tokens in 4.79 seconds\n",
            "Tokens per second: 63.24\n",
            "Draft token acceptance rate: 75.50%\n",
            "Generated 303 tokens in 5.30 seconds\n",
            "Tokens per second: 57.21\n",
            "Draft token acceptance rate: 75.50%\n",
            "Generated 303 tokens in 4.83 seconds\n",
            "Tokens per second: 62.71\n",
            "Draft token acceptance rate: 75.50%\n",
            "Average speculative decoding time: 4.97 seconds\n",
            "Average speculative tokens per second: 61.04\n",
            "Average baseline decoding time: 6.50 seconds\n",
            "Average baseline tokens per second: 38.46\n",
            "Speedup: 1.31x\n",
            "Latency reduction: 23.50%\n",
            "\n",
            "Benchmarking with 250 max tokens and 250 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 251 tokens in 5.63 seconds\n",
            "Tokens per second: 44.58\n",
            "Draft token acceptance rate: 50.00%\n",
            "Generated 251 tokens in 6.14 seconds\n",
            "Tokens per second: 40.91\n",
            "Draft token acceptance rate: 50.00%\n",
            "Generated 251 tokens in 5.63 seconds\n",
            "Tokens per second: 44.57\n",
            "Draft token acceptance rate: 50.00%\n",
            "Average speculative decoding time: 5.80 seconds\n",
            "Average speculative tokens per second: 43.34\n",
            "Average baseline decoding time: 6.50 seconds\n",
            "Average baseline tokens per second: 38.50\n",
            "Speedup: 1.12x\n",
            "Latency reduction: 10.70%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 259 tokens in 5.66 seconds\n",
            "Tokens per second: 45.76\n",
            "Draft token acceptance rate: 51.60%\n",
            "Generated 259 tokens in 6.27 seconds\n",
            "Tokens per second: 41.33\n",
            "Draft token acceptance rate: 51.60%\n",
            "Generated 259 tokens in 5.62 seconds\n",
            "Tokens per second: 46.11\n",
            "Draft token acceptance rate: 51.60%\n",
            "Average speculative decoding time: 5.85 seconds\n",
            "Average speculative tokens per second: 44.39\n",
            "Average baseline decoding time: 6.51 seconds\n",
            "Average baseline tokens per second: 38.42\n",
            "Speedup: 1.11x\n",
            "Latency reduction: 10.14%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 253 tokens in 5.84 seconds\n",
            "Tokens per second: 43.31\n",
            "Draft token acceptance rate: 50.40%\n",
            "Generated 253 tokens in 5.92 seconds\n",
            "Tokens per second: 42.75\n",
            "Draft token acceptance rate: 50.40%\n",
            "Generated 253 tokens in 5.75 seconds\n",
            "Tokens per second: 44.01\n",
            "Draft token acceptance rate: 50.40%\n",
            "Average speculative decoding time: 5.84 seconds\n",
            "Average speculative tokens per second: 43.35\n",
            "Average baseline decoding time: 6.47 seconds\n",
            "Average baseline tokens per second: 38.63\n",
            "Speedup: 1.11x\n",
            "Latency reduction: 9.80%\n",
            "\n",
            "Benchmarking with 500 max tokens and 10 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 501 tokens in 16.40 seconds\n",
            "Tokens per second: 30.55\n",
            "Draft token acceptance rate: 98.04%\n",
            "Generated 501 tokens in 16.69 seconds\n",
            "Tokens per second: 30.02\n",
            "Draft token acceptance rate: 98.04%\n",
            "Generated 501 tokens in 16.32 seconds\n",
            "Tokens per second: 30.69\n",
            "Draft token acceptance rate: 98.04%\n",
            "Average speculative decoding time: 16.47 seconds\n",
            "Average speculative tokens per second: 30.42\n",
            "Average baseline decoding time: 13.20 seconds\n",
            "Average baseline tokens per second: 37.88\n",
            "Speedup: 0.80x\n",
            "Latency reduction: -24.79%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 509 tokens in 17.06 seconds\n",
            "Tokens per second: 29.84\n",
            "Draft token acceptance rate: 99.61%\n",
            "Generated 509 tokens in 17.35 seconds\n",
            "Tokens per second: 29.33\n",
            "Draft token acceptance rate: 99.61%\n",
            "Generated 509 tokens in 17.21 seconds\n",
            "Tokens per second: 29.58\n",
            "Draft token acceptance rate: 99.61%\n",
            "Average speculative decoding time: 17.21 seconds\n",
            "Average speculative tokens per second: 29.58\n",
            "Average baseline decoding time: 13.15 seconds\n",
            "Average baseline tokens per second: 38.04\n",
            "Speedup: 0.76x\n",
            "Latency reduction: -30.89%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 503 tokens in 16.86 seconds\n",
            "Tokens per second: 29.83\n",
            "Draft token acceptance rate: 98.43%\n",
            "Generated 503 tokens in 16.86 seconds\n",
            "Tokens per second: 29.83\n",
            "Draft token acceptance rate: 98.43%\n",
            "Generated 503 tokens in 16.68 seconds\n",
            "Tokens per second: 30.15\n",
            "Draft token acceptance rate: 98.43%\n",
            "Average speculative decoding time: 16.81 seconds\n",
            "Average speculative tokens per second: 29.93\n",
            "Average baseline decoding time: 13.24 seconds\n",
            "Average baseline tokens per second: 37.76\n",
            "Speedup: 0.79x\n",
            "Latency reduction: -26.89%\n",
            "\n",
            "Benchmarking with 500 max tokens and 25 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 501 tokens in 10.01 seconds\n",
            "Tokens per second: 50.05\n",
            "Draft token acceptance rate: 95.24%\n",
            "Generated 501 tokens in 10.26 seconds\n",
            "Tokens per second: 48.84\n",
            "Draft token acceptance rate: 95.24%\n",
            "Generated 501 tokens in 10.79 seconds\n",
            "Tokens per second: 46.42\n",
            "Draft token acceptance rate: 95.24%\n",
            "Average speculative decoding time: 10.35 seconds\n",
            "Average speculative tokens per second: 48.43\n",
            "Average baseline decoding time: 14.68 seconds\n",
            "Average baseline tokens per second: 34.78\n",
            "Speedup: 1.42x\n",
            "Latency reduction: 29.49%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 509 tokens in 10.55 seconds\n",
            "Tokens per second: 48.23\n",
            "Draft token acceptance rate: 96.76%\n",
            "Generated 509 tokens in 10.48 seconds\n",
            "Tokens per second: 48.59\n",
            "Draft token acceptance rate: 96.76%\n",
            "Generated 509 tokens in 10.27 seconds\n",
            "Tokens per second: 49.56\n",
            "Draft token acceptance rate: 96.76%\n",
            "Average speculative decoding time: 10.44 seconds\n",
            "Average speculative tokens per second: 48.78\n",
            "Average baseline decoding time: 13.46 seconds\n",
            "Average baseline tokens per second: 37.17\n",
            "Speedup: 1.29x\n",
            "Latency reduction: 22.45%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 503 tokens in 10.43 seconds\n",
            "Tokens per second: 48.20\n",
            "Draft token acceptance rate: 95.62%\n",
            "Generated 503 tokens in 10.35 seconds\n",
            "Tokens per second: 48.61\n",
            "Draft token acceptance rate: 95.62%\n",
            "Generated 503 tokens in 10.13 seconds\n",
            "Tokens per second: 49.68\n",
            "Draft token acceptance rate: 95.62%\n",
            "Average speculative decoding time: 10.30 seconds\n",
            "Average speculative tokens per second: 48.82\n",
            "Average baseline decoding time: 13.15 seconds\n",
            "Average baseline tokens per second: 38.01\n",
            "Speedup: 1.28x\n",
            "Latency reduction: 21.67%\n",
            "\n",
            "Benchmarking with 500 max tokens and 100 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 501 tokens in 7.52 seconds\n",
            "Tokens per second: 66.60\n",
            "Draft token acceptance rate: 83.33%\n",
            "Generated 501 tokens in 7.97 seconds\n",
            "Tokens per second: 62.89\n",
            "Draft token acceptance rate: 83.33%\n",
            "Generated 501 tokens in 7.99 seconds\n",
            "Tokens per second: 62.67\n",
            "Draft token acceptance rate: 83.33%\n",
            "Average speculative decoding time: 7.83 seconds\n",
            "Average speculative tokens per second: 64.04\n",
            "Average baseline decoding time: 13.11 seconds\n",
            "Average baseline tokens per second: 38.15\n",
            "Speedup: 1.67x\n",
            "Latency reduction: 40.26%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 509 tokens in 7.98 seconds\n",
            "Tokens per second: 63.77\n",
            "Draft token acceptance rate: 84.67%\n",
            "Generated 509 tokens in 7.46 seconds\n",
            "Tokens per second: 68.25\n",
            "Draft token acceptance rate: 84.67%\n",
            "Generated 509 tokens in 8.12 seconds\n",
            "Tokens per second: 62.68\n",
            "Draft token acceptance rate: 84.67%\n",
            "Average speculative decoding time: 7.86 seconds\n",
            "Average speculative tokens per second: 64.89\n",
            "Average baseline decoding time: 13.13 seconds\n",
            "Average baseline tokens per second: 38.08\n",
            "Speedup: 1.67x\n",
            "Latency reduction: 40.17%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 503 tokens in 8.07 seconds\n",
            "Tokens per second: 62.31\n",
            "Draft token acceptance rate: 83.67%\n",
            "Generated 503 tokens in 7.99 seconds\n",
            "Tokens per second: 62.97\n",
            "Draft token acceptance rate: 83.67%\n",
            "Generated 503 tokens in 7.47 seconds\n",
            "Tokens per second: 67.33\n",
            "Draft token acceptance rate: 83.67%\n",
            "Average speculative decoding time: 7.85 seconds\n",
            "Average speculative tokens per second: 64.19\n",
            "Average baseline decoding time: 13.28 seconds\n",
            "Average baseline tokens per second: 37.66\n",
            "Speedup: 1.69x\n",
            "Latency reduction: 40.92%\n",
            "\n",
            "Benchmarking with 500 max tokens and 250 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 501 tokens in 8.46 seconds\n",
            "Tokens per second: 59.22\n",
            "Draft token acceptance rate: 66.67%\n",
            "Generated 501 tokens in 8.96 seconds\n",
            "Tokens per second: 55.94\n",
            "Draft token acceptance rate: 66.67%\n",
            "Generated 501 tokens in 8.97 seconds\n",
            "Tokens per second: 55.84\n",
            "Draft token acceptance rate: 66.67%\n",
            "Average speculative decoding time: 8.80 seconds\n",
            "Average speculative tokens per second: 56.99\n",
            "Average baseline decoding time: 13.09 seconds\n",
            "Average baseline tokens per second: 38.19\n",
            "Speedup: 1.49x\n",
            "Latency reduction: 32.81%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 509 tokens in 9.00 seconds\n",
            "Tokens per second: 56.56\n",
            "Draft token acceptance rate: 67.73%\n",
            "Generated 509 tokens in 8.88 seconds\n",
            "Tokens per second: 57.35\n",
            "Draft token acceptance rate: 67.73%\n",
            "Generated 509 tokens in 8.56 seconds\n",
            "Tokens per second: 59.43\n",
            "Draft token acceptance rate: 67.73%\n",
            "Average speculative decoding time: 8.81 seconds\n",
            "Average speculative tokens per second: 57.77\n",
            "Average baseline decoding time: 13.20 seconds\n",
            "Average baseline tokens per second: 37.88\n",
            "Speedup: 1.50x\n",
            "Latency reduction: 33.22%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 503 tokens in 8.45 seconds\n",
            "Tokens per second: 59.53\n",
            "Draft token acceptance rate: 66.93%\n",
            "Generated 503 tokens in 9.00 seconds\n",
            "Tokens per second: 55.89\n",
            "Draft token acceptance rate: 66.93%\n",
            "Generated 503 tokens in 9.07 seconds\n",
            "Tokens per second: 55.47\n",
            "Draft token acceptance rate: 66.93%\n",
            "Average speculative decoding time: 8.84 seconds\n",
            "Average speculative tokens per second: 56.95\n",
            "Average baseline decoding time: 13.11 seconds\n",
            "Average baseline tokens per second: 38.14\n",
            "Speedup: 1.48x\n",
            "Latency reduction: 32.57%\n",
            "\n",
            "Benchmarking with 1000 max tokens and 10 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 1001 tokens in 57.94 seconds\n",
            "Tokens per second: 17.28\n",
            "Draft token acceptance rate: 99.01%\n",
            "Generated 1001 tokens in 56.11 seconds\n",
            "Tokens per second: 17.84\n",
            "Draft token acceptance rate: 99.01%\n",
            "Generated 1001 tokens in 52.46 seconds\n",
            "Tokens per second: 19.08\n",
            "Draft token acceptance rate: 99.01%\n",
            "Average speculative decoding time: 55.51 seconds\n",
            "Average speculative tokens per second: 18.06\n",
            "Average baseline decoding time: 27.89 seconds\n",
            "Average baseline tokens per second: 35.85\n",
            "Speedup: 0.50x\n",
            "Latency reduction: -99.00%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 1009 tokens in 53.48 seconds\n",
            "Tokens per second: 18.87\n",
            "Draft token acceptance rate: 99.80%\n",
            "Generated 1009 tokens in 53.72 seconds\n",
            "Tokens per second: 18.78\n",
            "Draft token acceptance rate: 99.80%\n",
            "Generated 1009 tokens in 54.10 seconds\n",
            "Tokens per second: 18.65\n",
            "Draft token acceptance rate: 99.80%\n",
            "Average speculative decoding time: 53.77 seconds\n",
            "Average speculative tokens per second: 18.77\n",
            "Average baseline decoding time: 27.92 seconds\n",
            "Average baseline tokens per second: 35.82\n",
            "Speedup: 0.52x\n",
            "Latency reduction: -92.58%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 1003 tokens in 53.17 seconds\n",
            "Tokens per second: 18.86\n",
            "Draft token acceptance rate: 99.21%\n",
            "Generated 1003 tokens in 52.98 seconds\n",
            "Tokens per second: 18.93\n",
            "Draft token acceptance rate: 99.21%\n",
            "Generated 1003 tokens in 53.07 seconds\n",
            "Tokens per second: 18.90\n",
            "Draft token acceptance rate: 99.21%\n",
            "Average speculative decoding time: 53.08 seconds\n",
            "Average speculative tokens per second: 18.88\n",
            "Average baseline decoding time: 27.90 seconds\n",
            "Average baseline tokens per second: 35.84\n",
            "Speedup: 0.53x\n",
            "Latency reduction: -90.24%\n",
            "\n",
            "Benchmarking with 1000 max tokens and 25 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 1001 tokens in 27.69 seconds\n",
            "Tokens per second: 36.15\n",
            "Draft token acceptance rate: 97.56%\n",
            "Generated 1001 tokens in 27.59 seconds\n",
            "Tokens per second: 36.29\n",
            "Draft token acceptance rate: 97.56%\n",
            "Generated 1001 tokens in 27.75 seconds\n",
            "Tokens per second: 36.07\n",
            "Draft token acceptance rate: 97.56%\n",
            "Average speculative decoding time: 27.68 seconds\n",
            "Average speculative tokens per second: 36.16\n",
            "Average baseline decoding time: 28.04 seconds\n",
            "Average baseline tokens per second: 35.67\n",
            "Speedup: 1.01x\n",
            "Latency reduction: 1.28%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 1009 tokens in 28.80 seconds\n",
            "Tokens per second: 35.03\n",
            "Draft token acceptance rate: 98.34%\n",
            "Generated 1009 tokens in 28.78 seconds\n",
            "Tokens per second: 35.06\n",
            "Draft token acceptance rate: 98.34%\n",
            "Generated 1009 tokens in 28.36 seconds\n",
            "Tokens per second: 35.58\n",
            "Draft token acceptance rate: 98.34%\n",
            "Average speculative decoding time: 28.65 seconds\n",
            "Average speculative tokens per second: 35.22\n",
            "Average baseline decoding time: 27.91 seconds\n",
            "Average baseline tokens per second: 35.83\n",
            "Speedup: 0.97x\n",
            "Latency reduction: -2.66%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 1003 tokens in 27.77 seconds\n",
            "Tokens per second: 36.12\n",
            "Draft token acceptance rate: 97.76%\n",
            "Generated 1003 tokens in 28.29 seconds\n",
            "Tokens per second: 35.45\n",
            "Draft token acceptance rate: 97.76%\n",
            "Generated 1003 tokens in 28.29 seconds\n",
            "Tokens per second: 35.46\n",
            "Draft token acceptance rate: 97.76%\n",
            "Average speculative decoding time: 28.12 seconds\n",
            "Average speculative tokens per second: 35.64\n",
            "Average baseline decoding time: 28.03 seconds\n",
            "Average baseline tokens per second: 35.68\n",
            "Speedup: 1.00x\n",
            "Latency reduction: -0.31%\n",
            "\n",
            "Benchmarking with 1000 max tokens and 100 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 1001 tokens in 15.99 seconds\n",
            "Tokens per second: 62.60\n",
            "Draft token acceptance rate: 90.91%\n",
            "Generated 1001 tokens in 16.06 seconds\n",
            "Tokens per second: 62.33\n",
            "Draft token acceptance rate: 90.91%\n",
            "Generated 1001 tokens in 16.52 seconds\n",
            "Tokens per second: 60.61\n",
            "Draft token acceptance rate: 90.91%\n",
            "Average speculative decoding time: 16.19 seconds\n",
            "Average speculative tokens per second: 61.84\n",
            "Average baseline decoding time: 27.96 seconds\n",
            "Average baseline tokens per second: 35.77\n",
            "Speedup: 1.73x\n",
            "Latency reduction: 42.09%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 1009 tokens in 16.69 seconds\n",
            "Tokens per second: 60.46\n",
            "Draft token acceptance rate: 91.64%\n",
            "Generated 1009 tokens in 16.55 seconds\n",
            "Tokens per second: 60.97\n",
            "Draft token acceptance rate: 91.64%\n",
            "Generated 1009 tokens in 16.33 seconds\n",
            "Tokens per second: 61.80\n",
            "Draft token acceptance rate: 91.64%\n",
            "Average speculative decoding time: 16.52 seconds\n",
            "Average speculative tokens per second: 61.07\n",
            "Average baseline decoding time: 27.92 seconds\n",
            "Average baseline tokens per second: 35.81\n",
            "Speedup: 1.69x\n",
            "Latency reduction: 40.83%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 1003 tokens in 16.17 seconds\n",
            "Tokens per second: 62.01\n",
            "Draft token acceptance rate: 91.09%\n",
            "Generated 1003 tokens in 16.58 seconds\n",
            "Tokens per second: 60.49\n",
            "Draft token acceptance rate: 91.09%\n",
            "Generated 1003 tokens in 16.14 seconds\n",
            "Tokens per second: 62.15\n",
            "Draft token acceptance rate: 91.09%\n",
            "Average speculative decoding time: 16.30 seconds\n",
            "Average speculative tokens per second: 61.48\n",
            "Average baseline decoding time: 27.92 seconds\n",
            "Average baseline tokens per second: 35.82\n",
            "Speedup: 1.71x\n",
            "Latency reduction: 41.62%\n",
            "\n",
            "Benchmarking with 1000 max tokens and 250 speculative tokens:\n",
            "\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 1001 tokens in 15.80 seconds\n",
            "Tokens per second: 63.36\n",
            "Draft token acceptance rate: 80.00%\n",
            "Generated 1001 tokens in 15.95 seconds\n",
            "Tokens per second: 62.76\n",
            "Draft token acceptance rate: 80.00%\n",
            "Generated 1001 tokens in 15.33 seconds\n",
            "Tokens per second: 65.29\n",
            "Draft token acceptance rate: 80.00%\n",
            "Average speculative decoding time: 15.70 seconds\n",
            "Average speculative tokens per second: 63.79\n",
            "Average baseline decoding time: 27.89 seconds\n",
            "Average baseline tokens per second: 35.85\n",
            "Speedup: 1.78x\n",
            "Latency reduction: 43.73%\n",
            "\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 1009 tokens in 15.60 seconds\n",
            "Tokens per second: 64.69\n",
            "Draft token acceptance rate: 80.64%\n",
            "Generated 1009 tokens in 15.89 seconds\n",
            "Tokens per second: 63.49\n",
            "Draft token acceptance rate: 80.64%\n",
            "Generated 1009 tokens in 15.54 seconds\n",
            "Tokens per second: 64.95\n",
            "Draft token acceptance rate: 80.64%\n",
            "Average speculative decoding time: 15.68 seconds\n",
            "Average speculative tokens per second: 64.37\n",
            "Average baseline decoding time: 27.88 seconds\n",
            "Average baseline tokens per second: 35.87\n",
            "Speedup: 1.78x\n",
            "Latency reduction: 43.77%\n",
            "\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 1003 tokens in 15.91 seconds\n",
            "Tokens per second: 63.04\n",
            "Draft token acceptance rate: 80.16%\n",
            "Generated 1003 tokens in 15.57 seconds\n",
            "Tokens per second: 64.41\n",
            "Draft token acceptance rate: 80.16%\n",
            "Generated 1003 tokens in 15.24 seconds\n",
            "Tokens per second: 65.81\n",
            "Draft token acceptance rate: 80.16%\n",
            "Average speculative decoding time: 15.58 seconds\n",
            "Average speculative tokens per second: 64.35\n",
            "Average baseline decoding time: 27.89 seconds\n",
            "Average baseline tokens per second: 35.85\n",
            "Speedup: 1.79x\n",
            "Latency reduction: 44.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus"
      ],
      "metadata": {
        "id": "PaKowOEevGiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings to achieve 85%+ draft acceptance rate and about 1.3x speedup\n",
        "target_model_name = \"EleutherAI/pythia-1.4b-deduped\"  # Larger target model\n",
        "draft_model_name = \"EleutherAI/pythia-160m-deduped\"   # Smaller draft model\n",
        "\n",
        "\n",
        "# Initialize speculative decoder\n",
        "decoder = SpeculativeDecoder(\n",
        "    target_model_name=target_model_name,\n",
        "    draft_model_name=draft_model_name,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Test prompts\n",
        "test_prompts = [\n",
        "    \"The future of Artificial Intelligence is\",\n",
        "    \"Write a short story about a robot learning to feel emotions:\",\n",
        "    \"Write the lyrics to the song 'Happy Birthday'.\"\n",
        "]\n",
        "\n",
        "# Run benchmark on test prompts\n",
        "for i, prompt in enumerate(test_prompts):\n",
        "    print(f\"\\nBenchmarking Prompt {i+1}:\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "\n",
        "    results = decoder.bonus_benchmark(\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,\n",
        "        num_speculative_tokens=16,\n",
        "        num_runs=3,\n",
        "        compare_baseline=True\n",
        "    )\n",
        "\n",
        "    print(f\"Average speculative decoding time: {results['speculative']['avg_time']:.2f} seconds\")\n",
        "    print(f\"Average speculative tokens per second: {results['speculative']['avg_tokens_per_second']:.2f}\")\n",
        "\n",
        "    if results[\"baseline\"] is not None:\n",
        "        print(f\"Average baseline decoding time: {results['baseline']['avg_time']:.2f} seconds\")\n",
        "        print(f\"Average baseline tokens per second: {results['baseline']['avg_tokens_per_second']:.2f}\")\n",
        "        print(f\"Speedup: {results['speedup']:.2f}x\")\n",
        "        print(f\"Latency reduction: {results['latency_reduction']:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cz18Q0OgGT3",
        "outputId": "830d110f-1506-4b41-82e0-d58112e75047"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Benchmarking Prompt 1:\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 113 tokens in 2.17 seconds\n",
            "Tokens per second: 52.09\n",
            "Draft token acceptance rate: 87.50%\n",
            "Generated 113 tokens in 2.06 seconds\n",
            "Tokens per second: 54.77\n",
            "Draft token acceptance rate: 87.50%\n",
            "Generated 113 tokens in 2.07 seconds\n",
            "Tokens per second: 54.50\n",
            "Draft token acceptance rate: 87.50%\n",
            "Average speculative decoding time: 2.10 seconds\n",
            "Average speculative tokens per second: 53.76\n",
            "Average baseline decoding time: 2.88 seconds\n",
            "Average baseline tokens per second: 35.36\n",
            "Speedup: 1.37x\n",
            "Latency reduction: 26.85%\n",
            "\n",
            "Benchmarking Prompt 2:\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 105 tokens in 2.68 seconds\n",
            "Tokens per second: 39.20\n",
            "Draft token acceptance rate: 92.86%\n",
            "Generated 105 tokens in 2.62 seconds\n",
            "Tokens per second: 40.07\n",
            "Draft token acceptance rate: 92.86%\n",
            "Generated 105 tokens in 2.35 seconds\n",
            "Tokens per second: 44.60\n",
            "Draft token acceptance rate: 92.86%\n",
            "Average speculative decoding time: 2.55 seconds\n",
            "Average speculative tokens per second: 41.26\n",
            "Average baseline decoding time: 2.66 seconds\n",
            "Average baseline tokens per second: 37.76\n",
            "Speedup: 1.04x\n",
            "Latency reduction: 4.19%\n",
            "\n",
            "Benchmarking Prompt 3:\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 115 tokens in 2.14 seconds\n",
            "Tokens per second: 53.84\n",
            "Draft token acceptance rate: 89.06%\n",
            "Generated 115 tokens in 2.08 seconds\n",
            "Tokens per second: 55.39\n",
            "Draft token acceptance rate: 89.06%\n",
            "Generated 115 tokens in 2.59 seconds\n",
            "Tokens per second: 44.47\n",
            "Draft token acceptance rate: 89.06%\n",
            "Average speculative decoding time: 2.27 seconds\n",
            "Average speculative tokens per second: 51.19\n",
            "Average baseline decoding time: 2.52 seconds\n",
            "Average baseline tokens per second: 39.63\n",
            "Speedup: 1.11x\n",
            "Latency reduction: 10.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test speculative decoding on new models\n",
        "target_model_name = \"gpt2-large\"\n",
        "draft_model_name = \"gpt2-medium\"\n",
        "\n",
        "\n",
        "# Initialize speculative decoder\n",
        "decoder = SpeculativeDecoder(\n",
        "    target_model_name=target_model_name,\n",
        "    draft_model_name=draft_model_name,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Test prompts\n",
        "test_prompts = [\n",
        "    \"The future of Artificial Intelligence is\",\n",
        "    \"Write a short story about a robot learning to feel emotions:\",\n",
        "    \"Write the lyrics to the song 'Happy Birthday'.\"\n",
        "]\n",
        "\n",
        "# Run benchmark on test prompts\n",
        "for i, prompt in enumerate(test_prompts):\n",
        "    print(f\"\\nBenchmarking Prompt {i+1}:\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "\n",
        "    results = decoder.bonus_benchmark(\n",
        "        prompt=prompt,\n",
        "        max_tokens=250,\n",
        "        num_speculative_tokens=20,\n",
        "        num_runs=3,\n",
        "        compare_baseline=True\n",
        "    )\n",
        "\n",
        "    print(f\"Average speculative decoding time: {results['speculative']['avg_time']:.2f} seconds\")\n",
        "    print(f\"Average speculative tokens per second: {results['speculative']['avg_tokens_per_second']:.2f}\")\n",
        "\n",
        "    if results[\"baseline\"] is not None:\n",
        "        print(f\"Average baseline decoding time: {results['baseline']['avg_time']:.2f} seconds\")\n",
        "        print(f\"Average baseline tokens per second: {results['baseline']['avg_tokens_per_second']:.2f}\")\n",
        "        print(f\"Speedup: {results['speedup']:.2f}x\")\n",
        "        print(f\"Latency reduction: {results['latency_reduction']:.2f}%\")"
      ],
      "metadata": {
        "id": "Y1sEo2706O29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be5db5d-e502-4357-a44c-2cf2b8ebc631"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Benchmarking Prompt 1:\n",
            "Prompt: The future of Artificial Intelligence is\n",
            "Generated 262 tokens in 7.02 seconds\n",
            "Tokens per second: 37.35\n",
            "Draft token acceptance rate: 93.21%\n",
            "Generated 262 tokens in 6.74 seconds\n",
            "Tokens per second: 38.86\n",
            "Draft token acceptance rate: 93.21%\n",
            "Generated 262 tokens in 7.14 seconds\n",
            "Tokens per second: 36.69\n",
            "Draft token acceptance rate: 93.21%\n",
            "Average speculative decoding time: 6.97 seconds\n",
            "Average speculative tokens per second: 37.62\n",
            "Average baseline decoding time: 7.30 seconds\n",
            "Average baseline tokens per second: 34.30\n",
            "Speedup: 1.05x\n",
            "Latency reduction: 4.57%\n",
            "\n",
            "Benchmarking Prompt 2:\n",
            "Prompt: Write a short story about a robot learning to feel emotions:\n",
            "Generated 267 tokens in 12.67 seconds\n",
            "Tokens per second: 21.07\n",
            "Draft token acceptance rate: 50.20%\n",
            "Generated 267 tokens in 12.75 seconds\n",
            "Tokens per second: 20.94\n",
            "Draft token acceptance rate: 50.20%\n",
            "Generated 267 tokens in 12.39 seconds\n",
            "Tokens per second: 21.55\n",
            "Draft token acceptance rate: 50.20%\n",
            "Average speculative decoding time: 12.61 seconds\n",
            "Average speculative tokens per second: 21.18\n",
            "Average baseline decoding time: 7.00 seconds\n",
            "Average baseline tokens per second: 35.81\n",
            "Speedup: 0.55x\n",
            "Latency reduction: -80.27%\n",
            "\n",
            "Benchmarking Prompt 3:\n",
            "Prompt: Write the lyrics to the song 'Happy Birthday'.\n",
            "Generated 265 tokens in 8.98 seconds\n",
            "Tokens per second: 29.50\n",
            "Draft token acceptance rate: 71.94%\n",
            "Generated 265 tokens in 9.04 seconds\n",
            "Tokens per second: 29.31\n",
            "Draft token acceptance rate: 71.94%\n",
            "Generated 265 tokens in 9.60 seconds\n",
            "Tokens per second: 27.59\n",
            "Draft token acceptance rate: 71.94%\n",
            "Average speculative decoding time: 9.22 seconds\n",
            "Average speculative tokens per second: 28.78\n",
            "Average baseline decoding time: 7.63 seconds\n",
            "Average baseline tokens per second: 32.84\n",
            "Speedup: 0.83x\n",
            "Latency reduction: -20.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZiJhJlEWjlG4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}